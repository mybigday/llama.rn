export const MODELS = {
  SMOL_LM_3: {
    name: 'SmolLM3 3B (Q4_K_M)',
    repo: 'ggml-org/SmolLM3-3B-GGUF',
    filename: 'SmolLM3-Q4_K_M.gguf',
    mmproj: undefined,
    size: '1.78GB',
  },
  GEMMA_3N_E2B: {
    name: 'Gemma 3N E2B IT (Q3_K_M)',
    repo: 'unsloth/gemma-3n-E2B-it-GGUF',
    filename: 'gemma-3n-E2B-it-Q3_K_M.gguf',
    mmproj: undefined,
    size: '2.31GB',
  },
  GEMMA_3N_E4B: {
    name: 'Gemma 3N E4B IT (Q3_K_M)',
    repo: 'unsloth/gemma-3n-E4B-it-GGUF',
    filename: 'gemma-3n-E4B-it-Q3_K_M.gguf',
    mmproj: undefined,
    size: '3.44GB',
  },
  QWEN_3_4B: {
    name: 'Qwen 3 4B (Q3_K_M)',
    repo: 'unsloth/Qwen3-4B-GGUF',
    filename: 'Qwen3-4B-Q3_K_M.gguf',
    mmproj: undefined,
    size: '1.93GB',
  },
  SMOL_VLM_500M: {
    name: 'SmolVLM 500M Instruct (Q8_0)',
    repo: 'ggml-org/SmolVLM-500M-Instruct-GGUF',
    filename: 'SmolVLM-500M-Instruct-Q8_0.gguf',
    mmproj: 'mmproj-SmolVLM-500M-Instruct-Q8_0.gguf',
    size: '416MB',
  },
  SMOL_VLM_2_2B: {
    name: 'SmolVLM2 2.2B Instruct (Q4_K_M)',
    repo: 'ggml-org/SmolVLM2-2.2B-Instruct-GGUF',
    filename: 'SmolVLM2-2.2B-Instruct-Q4_K_M.gguf',
    mmproj: 'mmproj-SmolVLM2-2.2B-Instruct-Q8_0.gguf',
    size: '1.8GB (model) + 565MB (mmproj)',
  },
  INTERNVL3_2B: {
    name: 'InternVL3 2B (Q8_0)',
    repo: 'ggml-org/InternVL3-2B-Instruct-GGUF',
    filename: 'InternVL3-2B-Instruct-Q8_0.gguf',
    mmproj: 'mmproj-InternVL3-2B-Instruct-Q8_0.gguf',
    size: '1.89GB (model) + 337MB (mmproj)',
  },
  QWEN2_5_VL_3B: {
    name: 'Qwen2.5 VL 3B (Q4_K_M)',
    repo: 'ggml-org/Qwen2.5-VL-3B-Instruct-GGUF',
    filename: 'Qwen2.5-VL-3B-Instruct-Q4_K_M.gguf',
    mmproj: 'mmproj-Qwen2.5-VL-3B-Instruct-Q8_0.gguf',
    size: '1.93GB (model) + 845MB (mmproj)',
  },
  QWEN2_5_OMNI_3B: {
    name: 'Qwen2.5 Omni 3B (Q4_K_M)',
    repo: 'ggml-org/Qwen2.5-Omni-3B-GGUF',
    filename: 'Qwen2.5-Omni-3B-Q4_K_M.gguf',
    mmproj: 'mmproj-Qwen2.5-Omni-3B-Q8_0.gguf',
    size: '2.1GB (model) + 1.54GB (mmproj)',
  },
  GEMMA_3_4B_QAT: {
    name: 'Gemma 3 4B IT QAT (Q3_K_M)',
    repo: 'unsloth/gemma-3-4b-it-qat-GGUF',
    filename: 'gemma-3-4b-it-qat-Q3_K_M.gguf',
    mmproj: 'mmproj-BF16.gguf',
    size: '1.95GB (model) + 881MB (mmproj)',
  },
  ULTRAVOX_V0_5_LLAMA_3_2_1B: {
    name: 'Ultravox V0.5 Llama 3.2 1B (Q4_K_M)',
    repo: 'ggml-org/ultravox-v0_5-llama-3_2-1b-GGUF',
    filename: 'Llama-3.2-1B-Instruct-Q4_K_M.gguf',
    mmproj: 'mmproj-ultravox-v0_5-llama-3_2-1b-f16.gguf',
    size: '808MB (model) + 1.37GB (mmproj)',
  },
  OUTE_TTS_0_3: {
    name: 'OuteTTS 0.3 500M (Q4_K_M) + WavTokenizer (Q5_1)',
    repo: 'OuteAI/OuteTTS-0.3-500M-GGUF',
    filename: 'OuteTTS-0.3-500M-Q4_K_M.gguf',
    mmproj: undefined,
    size: '454MB (model) + 70MB (vocoder)',
    vocoder: {
      repo: 'ggml-org/WavTokenizer',
      filename: 'WavTokenizer-Large-75-Q5_1.gguf',
      size: '70MB',
    },
  },
  EMBEDDINGGEMMA_300M: {
    name: 'EmbeddingGemma 300M (Q8_0)',
    repo: 'ggml-org/embeddinggemma-300M-GGUF',
    filename: 'embeddinggemma-300M-Q8_0.gguf',
    mmproj: undefined,
    size: '329MB',
    embedding: true,
  },
  NOMIC_EMBED_TEXT_V1_5: {
    name: 'Nomic Embed Text v1.5 (Q8_0)',
    repo: 'nomic-ai/nomic-embed-text-v1.5-GGUF',
    filename: 'nomic-embed-text-v1.5.Q8_0.gguf',
    mmproj: undefined,
    embedding: true,
    size: '146MB',
  },
  SNOWFLAKE_ARCTIC_EMBED_M_V1_5: {
    name: 'Snowflake Arctic Embed M v1.5 (Q8_0)',
    repo: 'Snowflake/snowflake-arctic-embed-m-v1.5',
    filename: 'gguf/snowflake-arctic-embed-m-v1.5-q8_0.gguf',
    mmproj: undefined,
    embedding: true,
    size: '118MB',
  },
  MIXEDBREAD_AI_EMBED_LARGE_V1: {
    name: 'MixedBread AI Embed Large v1 (F16)',
    repo: 'mixedbread-ai/mxbai-embed-large-v1',
    filename: 'gguf/mxbai-embed-large-v1-f16.gguf',
    mmproj: undefined,
    embedding: true,
    size: '670MB',
  },
  BGE_RERANKER_V2_M3: {
    name: 'BGE Reranker v2 M3 (Q8_0)',
    repo: 'gpustack/bge-reranker-v2-m3-GGUF',
    filename: 'bge-reranker-v2-m3-Q8_0.gguf',
    mmproj: undefined,
    ranking: true,
    size: '636MB',
  }
}

export const HUGGINGFACE_BASE_URL = 'https://huggingface.co'

export const getModelDownloadUrl = (repo: string, filename: string) =>
  `${HUGGINGFACE_BASE_URL}/${repo}/resolve/main/${filename}?download=true`
