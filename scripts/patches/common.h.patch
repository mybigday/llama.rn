--- common/common.h.orig	2025-12-18 13:39:06
+++ common/common.h	2025-12-18 13:39:58
@@ -307,6 +307,7 @@
 struct lm_ggml_opt_optimizer_params common_opt_lr_pars(void * userdata);

 struct common_params {
+    bool vocab_only               = false;
     int32_t n_predict             =    -1; // max. number of new tokens to predict, -1 == no limit
     int32_t n_ctx                 =     0; // context size, 0 == context the model was trained with
     int32_t n_batch               =  2048; // logical batch size for prompt processing (must be >=32 to use BLAS)
@@ -432,6 +433,9 @@
     bool no_host           = false; // bypass host buffer allowing extra buffers to be used

     bool single_turn       = false; // single turn chat conversation
+
+    llama_progress_callback progress_callback = nullptr;
+    void * progress_callback_user_data = nullptr;

     lm_ggml_type cache_type_k = LM_GGML_TYPE_F16; // KV cache data type for the K
     lm_ggml_type cache_type_v = LM_GGML_TYPE_F16; // KV cache data type for the V
