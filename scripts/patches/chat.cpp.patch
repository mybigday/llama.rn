--- common/chat.cpp.orig	2025-01-20 14:24:00
+++ common/chat.cpp	2025-01-20 14:24:00
@@ -615,6 +615,37 @@
     return tmpls->template_default->source();
 }

+common_chat_template_caps common_chat_templates_get_caps(const struct common_chat_templates * tmpls, const std::string & variant) {
+    common_chat_template_caps result;
+    const common_chat_template * tmpl = nullptr;
+
+    if (!variant.empty() && variant == "tool_use") {
+        tmpl = tmpls->template_tool_use.get();
+    } else {
+        tmpl = tmpls->template_default.get();
+    }
+
+    if (tmpl) {
+        auto caps = tmpl->original_caps();
+        result.supports_tools = caps.supports_tools;
+        result.supports_tool_calls = caps.supports_tool_calls;
+        result.supports_system_role = caps.supports_system_role;
+        result.supports_parallel_tool_calls = caps.supports_parallel_tool_calls;
+    }
+
+    return result;
+}
+
+bool common_chat_templates_has_variant(const struct common_chat_templates * tmpls, const std::string & variant) {
+    if (variant.empty() || variant == "default") {
+        return tmpls->template_default != nullptr;
+    }
+    if (variant == "tool_use") {
+        return tmpls->template_tool_use != nullptr;
+    }
+    return false;
+}
+
 common_chat_templates_ptr common_chat_templates_init(
     const struct llama_model * model,
     const std::string & chat_template_override,
